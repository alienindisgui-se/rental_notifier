name: Hourly Rental Scraping

on:
  schedule:
    - cron: '0 * * * *'
  workflow_dispatch:

jobs:
  scrape:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      actions: read # Required for artifact download/upload

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.10'

    # Attempt to download the artifact from a previous run.
    # This will fail on the very first run or if the artifact expired/was deleted,
    # but continue-on-error handles this.
    - name: Download previous listings artifact
      id: download-artifact
      uses: actions/download-artifact@v4
      continue-on-error: true # Allow the workflow to continue if the artifact is not found
      with:
        name: listings
        path: .
        # Removed run-id: logic, relying on default behavior or continue-on-error

    # Initialize listings file if the download failed or no artifact was found.
    # This ensures listings.json exists before the scraper runs.
    - name: Initialize listings file if not downloaded
      # Check if the download step did NOT succeed
      if: steps.download-artifact.outcome != 'success'
      run: |
        echo "[]" > listings.json
        echo "Initialized new empty listings.json file because previous artifact was not downloaded."

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install requests beautifulsoup4 discord.py

    - name: Run scraper
      env:
        DISCORD_BOT_TOKEN: ${{ secrets.DISCORD_BOT_TOKEN }}
        DISCORD_CHANNEL_ID: ${{ secrets.DISCORD_CHANNEL_ID }}
      run: python main.py

    # Upload the updated listings.json as an artifact for the next run
    - name: Upload new listings artifact
      uses: actions/upload-artifact@v4
      with:
        name: listings
        path: listings.json
        retention-days: 30 # Keep the artifact for 30 days
